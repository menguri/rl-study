# ----------------------
# 환경 설정 (Env Config)
# ----------------------
env_name: "InvertedPendulum-v5"  # 가장 쉬운 환경 (막대 세우기)

# ----------------------
# 모델 및 학습 알고리즘 설정 (Model & Training Method)
# ----------------------
model: "REINFORCE"  # Monte Carlo 방식의 Policy Gradient 사용
method: "default"   # 기본 REINFORCE 방식 (Baseline 추가 가능)

# ----------------------
# 하이퍼파라미터 설정 (Hyperparameters)
# ----------------------
batch_size: 32            # 배치 크기를 증가시켜 gradient 추정의 분산 감소 (간단한 환경에 적합)
buffer_size: 200000   # REINFORCE에서는 사용하지 않지만 다른 방법과 호환 가능

# ----------------------
# 학습률 및 최적화 관련 설정 (Learning Rate & Optimization)
# ----------------------
lr: 0.001            # 학습률 (기존과 동일, 환경에 따라 추가 조정 가능)
gamma: 0.99           # 할인 계수 (미래 보상의 가중치)
entropy_coeff: 0.02   # 탐사 성향을 높이기 위해 Entropy 계수를 약간 증가

# ----------------------
# Epsilon-Greedy Exploration (탐색 설정)
# ----------------------
# REINFORCE 방식에서는 사용하지 않으므로 주석 처리
# epsilon_init: 1.0
# epsilon_min: 0.1
# epsilon_decay: 0.995

# ----------------------
# 학습 단계 및 업데이트 설정 (Training Steps & Updates)
# ----------------------
n_step: 3000000         # 간단한 환경에 맞춰 전체 학습 스텝 수를 감소
n_train_start: 1000     # 학습 시작 전 최소 스텝 수를 감소
# target_update_freq: 1000  # REINFORCE에서는 사용하지 않음

# ----------------------
# 평가 및 테스트 주기 (Evaluation & Testing)
# ----------------------
test_freq: 1000         # 환경이 간단하므로 평가 주기를 더 자주 진행
total_episodes: 50000    # 총 에피소드 수도 간단한 환경에 맞춰 감소
