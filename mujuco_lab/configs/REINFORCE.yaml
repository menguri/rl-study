# ----------------------
# 환경 설정 (Env Config)
# ----------------------
# 사용 가능한 MuJoCo 환경 예시:
# env_name: "Walker2d-v5"      # 2족 보행, 중간 난이도
env_name: "InvertedPendulum-v5"  # 가장 쉬운 환경 (막대 세우기)
# env_name: "Swimmer-v5"       # 물속에서 움직이기, 난이도 낮음
# env_name: "Reacher-v5"       # 목표 지점 도달, 난이도 중간
# env_name: "HalfCheetah-v5"   # 빠르게 움직이기, 난이도 높음
# env_name: "Hopper-v5"        # 현재 사용 중인 환경 (한 발로 점프)
# env_name: "Hopper-v5"  # Walker2d-v5 사용하려면 주석 변경

# ----------------------
# 모델 및 학습 알고리즘 설정 (Model & Training Method)
# ----------------------
model: "REINFORCE"  # Monte Carlo 방식의 Policy Gradient 사용
method: "default"   # 기본 REINFORCE 방식 (Baseline 추가 가능)

# ----------------------
# 하이퍼파라미터 설정 (Hyperparameters)
# ----------------------
batch_size: 32            # 학습 배치 크기
buffer_size: 200000   # REINFORCE에서는 사용하지 않지만 다른 방법과 호환 가능

# ----------------------
# 학습률 및 최적화 관련 설정 (Learning Rate & Optimization)
# ----------------------
lr: 0.0003            # 기존보다 학습률 증가 (REINFORCE는 variance가 크기 때문)
gamma: 0.99           # 할인 계수 (미래 보상의 가중치 조절)
entropy_coeff: 0.01   # Entropy 조정 계수

# ----------------------
# Epsilon-Greedy Exploration (탐색 설정)
# ----------------------
epsilon_init: 1.0     # 초기 탐색 확률 (탐욕적 정책에서 사용, REINFORCE에서는 미사용)
epsilon_min: 0.1      # 최소 탐색 확률
epsilon_decay: 0.995  # 탐색 확률 감소율

# ----------------------
# 학습 단계 및 업데이트 설정 (Training Steps & Updates)
# ----------------------
n_step: 5000000         # 총 학습 스텝 수
n_train_start: 2000     # 학습 시작 전, 샘플을 쌓아둘 최소 스텝 수
target_update_freq: 1000  # 타겟 네트워크 업데이트 주기 (REINFORCE에서는 미사용)

# ----------------------
# 평가 및 테스트 주기 (Evaluation & Testing)
# ----------------------
test_freq: 5000         # 테스트 주기 (주어진 스텝마다 평가 수행)
total_episodes: 30000   # 총 에피소드 수

